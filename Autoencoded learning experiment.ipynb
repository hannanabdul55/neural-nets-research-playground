{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3),\n",
    "    nn.FractionalMaxPool2d(2, output_ratio=(1/np.sqrt(2))),\n",
    "    nn.Conv2d(16, 32, 3),\n",
    "    nn.FractionalMaxPool2d(2, output_ratio=(1/np.sqrt(2))),\n",
    "    nn.Conv2d(32, 64, 3),\n",
    "    nn.FractionalMaxPool2d(2, output_ratio=(1/np.sqrt(2))),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3136, 1152),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1152, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "trainloader, testloader, classes = load_CIFAR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_p(op, y, model_p):\n",
    "    params = list(model_p.parameters())\n",
    "    return ce_loss(op, y) + (1/len(params))*(torch.norm(torch.cat([param.view(-1) for param in params]))) #+ torch.sum((1/len(params))*torch.exp(torch.abs(torch.cat([param.view(-1) for param in params]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_base(op, y, model_p):\n",
    "    return nn.CrossEntropyLoss(reduction='sum')(op, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 104.610\n",
      "[1,   600] loss: 88.707\n",
      "[2,   300] loss: 70.791\n",
      "[2,   600] loss: 55.179\n",
      "[3,   300] loss: 58.114\n",
      "[3,   600] loss: 52.912\n",
      "[4,   300] loss: 58.328\n",
      "[4,   600] loss: 52.296\n",
      "[5,   300] loss: 48.578\n",
      "[5,   600] loss: 44.957\n",
      "[6,   300] loss: 35.368\n",
      "[6,   600] loss: 48.719\n",
      "[7,   300] loss: 32.967\n",
      "[7,   600] loss: 31.847\n",
      "[8,   300] loss: 26.959\n",
      "[8,   600] loss: 46.559\n",
      "[9,   300] loss: 32.831\n",
      "[9,   600] loss: 25.691\n",
      "[10,   300] loss: 25.837\n",
      "[10,   600] loss: 28.721\n",
      "[11,   300] loss: 15.989\n",
      "[11,   600] loss: 19.572\n",
      "[12,   300] loss: 14.056\n",
      "[12,   600] loss: 13.411\n",
      "[13,   300] loss: 20.452\n",
      "[13,   600] loss: 12.801\n",
      "[14,   300] loss: 5.306\n",
      "[14,   600] loss: 8.824\n",
      "[15,   300] loss: 4.021\n",
      "[15,   600] loss: 7.974\n",
      "[16,   300] loss: 4.622\n",
      "[16,   600] loss: 6.827\n",
      "[17,   300] loss: 4.869\n",
      "[17,   600] loss: 10.545\n",
      "[18,   300] loss: 3.993\n",
      "[18,   600] loss: 10.413\n",
      "[19,   300] loss: 4.356\n",
      "[19,   600] loss: 13.024\n",
      "[20,   300] loss: 4.642\n",
      "[20,   600] loss: 19.049\n",
      "[21,   300] loss: 3.343\n",
      "[21,   600] loss: 8.564\n",
      "[22,   300] loss: 1.851\n",
      "[22,   600] loss: 0.527\n",
      "[23,   300] loss: 2.307\n",
      "[23,   600] loss: 1.663\n",
      "[24,   300] loss: 1.923\n",
      "[24,   600] loss: 1.671\n",
      "[25,   300] loss: 0.905\n",
      "[25,   600] loss: 1.871\n",
      "[26,   300] loss: 6.574\n",
      "[26,   600] loss: 1.421\n",
      "[27,   300] loss: 8.855\n",
      "[27,   600] loss: 5.447\n",
      "[28,   300] loss: 2.652\n",
      "[28,   600] loss: 7.773\n",
      "[29,   300] loss: 1.912\n",
      "[29,   600] loss: 1.767\n",
      "[30,   300] loss: 0.457\n",
      "[30,   600] loss: 1.207\n"
     ]
    }
   ],
   "source": [
    "loss_history_base = train_model(model_t, trainloader, criterion_base, optimizer = optim.Adam(list(model_t.parameters()), lr=3e-4), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t_v2 = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3),\n",
    "    nn.FractionalMaxPool2d(2, output_ratio=(1/np.sqrt(2))),\n",
    "    nn.Conv2d(16, 32, 3),\n",
    "    nn.FractionalMaxPool2d(2, output_ratio=(1/np.sqrt(2))),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(5408, 1152),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1152, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 103.257\n",
      "[1,   600] loss: 99.812\n",
      "[2,   300] loss: 80.348\n",
      "[2,   600] loss: 92.498\n",
      "[3,   300] loss: 77.158\n",
      "[3,   600] loss: 48.082\n",
      "[4,   300] loss: 70.882\n",
      "[4,   600] loss: 62.246\n",
      "[5,   300] loss: 65.975\n",
      "[5,   600] loss: 40.804\n",
      "[6,   300] loss: 37.586\n",
      "[6,   600] loss: 44.484\n",
      "[7,   300] loss: 23.264\n",
      "[7,   600] loss: 45.321\n",
      "[8,   300] loss: 35.745\n",
      "[8,   600] loss: 34.502\n",
      "[9,   300] loss: 29.021\n",
      "[9,   600] loss: 32.116\n",
      "[10,   300] loss: 15.186\n",
      "[10,   600] loss: 20.507\n",
      "[11,   300] loss: 12.921\n",
      "[11,   600] loss: 11.523\n",
      "[12,   300] loss: 13.408\n",
      "[12,   600] loss: 9.024\n",
      "[13,   300] loss: 10.838\n",
      "[13,   600] loss: 16.665\n",
      "[14,   300] loss: 8.623\n",
      "[14,   600] loss: 9.927\n",
      "[15,   300] loss: 7.483\n",
      "[15,   600] loss: 2.652\n",
      "[16,   300] loss: 6.615\n",
      "[16,   600] loss: 5.945\n",
      "[17,   300] loss: 3.486\n",
      "[17,   600] loss: 9.223\n",
      "[18,   300] loss: 6.653\n",
      "[18,   600] loss: 2.350\n",
      "[19,   300] loss: 0.792\n",
      "[19,   600] loss: 10.142\n",
      "[20,   300] loss: 3.318\n",
      "[20,   600] loss: 3.033\n",
      "[21,   300] loss: 2.922\n",
      "[21,   600] loss: 7.920\n",
      "[22,   300] loss: 1.596\n",
      "[22,   600] loss: 2.012\n",
      "[23,   300] loss: 1.791\n",
      "[23,   600] loss: 1.732\n",
      "[24,   300] loss: 2.769\n",
      "[24,   600] loss: 2.447\n",
      "[25,   300] loss: 3.285\n",
      "[25,   600] loss: 8.233\n",
      "[26,   300] loss: 1.633\n",
      "[26,   600] loss: 2.970\n",
      "[27,   300] loss: 2.029\n",
      "[27,   600] loss: 1.117\n",
      "[28,   300] loss: 1.127\n",
      "[28,   600] loss: 1.880\n",
      "[29,   300] loss: 1.501\n",
      "[29,   600] loss: 2.745\n",
      "[30,   300] loss: 2.410\n",
      "[30,   600] loss: 0.206\n"
     ]
    }
   ],
   "source": [
    "# train v2 with only 2 conv layers\n",
    "loss_history_test = train_model(model_t_v2, trainloader, criterion_base, optimizer = optim.Adam(list(model_t_v2.parameters()), lr=3e-4), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-layer net f1 score: [0.74152953 0.81813701 0.62881679 0.49481481 0.64480874 0.59494949\n",
      " 0.77165354 0.75931842 0.78460128 0.75465498]\n",
      "3-conv-layer net accuracy: 0.6987\n",
      "2-conv-layer net f1 score: [0.73837209 0.78554217 0.5707989  0.48594569 0.61942257 0.58224016\n",
      " 0.71584461 0.74176955 0.80347116 0.73847803]\n",
      "2-conv-layer net accuracy: 0.6789\n"
     ]
    }
   ],
   "source": [
    "# ! conda list\n",
    "from sklearn.metrics import *\n",
    "y_v1, pred_y_v1 = get_predictions_ys(model_t, testloader)\n",
    "print(\"3-conv-layer net f1 score: \" + str(f1_score(y_v1, pred_y_v1, average=None)))\n",
    "print(\"3-conv-layer net accuracy: \" + str(accuracy_score(y_v1, pred_y_v1)))\n",
    "\n",
    "y_v2, pred_y_v2 = get_predictions_ys(model_t_v2, testloader)\n",
    "print(\"2-conv-layer net f1 score: \" + str(f1_score(y_v2, pred_y_v2, average=None)))\n",
    "print(\"2-conv-layer net accuracy: \" + str(accuracy_score(y_v2, pred_y_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for 3-conv layer\n",
      "Mean\n",
      "0.040802382\n",
      "standard deviation\n",
      "0.032516804\n",
      "Sparsity\n",
      "0.001633409380589741\n",
      "Stats for 2-conv layer\n",
      "Mean\n",
      "0.040571373\n",
      "standard deviation\n",
      "0.03255999\n",
      "Sparsity\n",
      "0.0016894062939450901\n"
     ]
    }
   ],
   "source": [
    "print(\"Stats for 3-conv layer\")\n",
    "print_stats(model_t)\n",
    "\n",
    "print(\"Stats for 2-conv layer\")\n",
    "print_stats(model_t_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoencoded = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3),\n",
    "    nn.FractionalMaxPool2d(2, output_ratio=(1/np.sqrt(2))),\n",
    "    nn.Conv2d(16, 32, 3),\n",
    "    nn.FractionalMaxPool2d(2, output_ratio=(1/np.sqrt(2))),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(5408, 1152),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1152, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 106.260\n",
      "[1,   600] loss: 92.253\n",
      "[2,   300] loss: 83.559\n",
      "[2,   600] loss: 67.769\n",
      "[3,   300] loss: 64.695\n",
      "[3,   600] loss: 63.473\n",
      "[4,   300] loss: 69.090\n",
      "[4,   600] loss: 50.230\n",
      "[5,   300] loss: 46.203\n",
      "[5,   600] loss: 45.633\n",
      "[6,   300] loss: 42.268\n",
      "[6,   600] loss: 39.803\n",
      "[7,   300] loss: 33.558\n",
      "[7,   600] loss: 28.456\n",
      "[8,   300] loss: 24.236\n",
      "[8,   600] loss: 15.206\n",
      "[9,   300] loss: 32.541\n",
      "[9,   600] loss: 19.956\n",
      "[10,   300] loss: 9.630\n",
      "[10,   600] loss: 18.619\n",
      "[11,   300] loss: 11.118\n",
      "[11,   600] loss: 23.304\n",
      "[12,   300] loss: 2.913\n",
      "[12,   600] loss: 18.697\n",
      "[13,   300] loss: 5.816\n",
      "[13,   600] loss: 15.566\n",
      "[14,   300] loss: 4.608\n",
      "[14,   600] loss: 1.940\n",
      "[15,   300] loss: 6.537\n",
      "[15,   600] loss: 3.817\n",
      "[16,   300] loss: 2.475\n",
      "[16,   600] loss: 6.695\n",
      "[17,   300] loss: 12.743\n",
      "[17,   600] loss: 5.929\n",
      "[18,   300] loss: 5.560\n",
      "[18,   600] loss: 9.534\n",
      "[19,   300] loss: 9.308\n",
      "[19,   600] loss: 6.872\n",
      "[20,   300] loss: 1.696\n",
      "[20,   600] loss: 14.989\n",
      "[21,   300] loss: 2.355\n",
      "[21,   600] loss: 0.205\n",
      "[22,   300] loss: 4.432\n",
      "[22,   600] loss: 5.145\n",
      "[23,   300] loss: 1.161\n",
      "[23,   600] loss: 4.387\n",
      "[24,   300] loss: 0.707\n",
      "[24,   600] loss: 1.031\n",
      "[25,   300] loss: 0.546\n",
      "[25,   600] loss: 1.140\n",
      "[26,   300] loss: 0.701\n",
      "[26,   600] loss: 5.363\n",
      "[27,   300] loss: 5.997\n",
      "[27,   600] loss: 0.123\n",
      "[28,   300] loss: 1.223\n",
      "[28,   600] loss: 4.759\n",
      "[29,   300] loss: 0.664\n",
      "[29,   600] loss: 1.069\n",
      "[30,   300] loss: 0.564\n",
      "[30,   600] loss: 1.804\n"
     ]
    }
   ],
   "source": [
    "# train v2 with only 2 conv layers\n",
    "encoder_loss_history_test = train_model_self_reg(model_autoencoded, trainloader, criterion_base, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for encoded layer\n",
      "Mean\n",
      "0.040562984\n",
      "standard deviation\n",
      "0.032107852\n",
      "Sparsity\n",
      "0.0015999022854130515\n",
      "encoded-layer net f1 score: [0.71361502 0.78433367 0.58363731 0.49614644 0.60639361 0.55636896\n",
      " 0.73207931 0.71525247 0.78912214 0.72831816]\n",
      "encoded-layer net accuracy: 0.6701\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-63f8db28ebd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoded-layer net accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions_ys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3-conv-layer net f1 score: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3-conv-layer net accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y_v1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_t' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Stats for encoded layer\")\n",
    "print_stats(model_autoencoded)\n",
    "\n",
    "y_enc, pred_y_enc = get_predictions_ys(model_autoencoded, testloader)\n",
    "print(\"encoded-layer net f1 score: \" + str(f1_score(y_enc, pred_y_enc, average=None)))\n",
    "print(\"encoded-layer net accuracy: \" + str(accuracy_score(y_enc, pred_y_enc)))\n",
    "\n",
    "y_v1, pred_y_v1 = get_predictions_ys(model_t, testloader)\n",
    "print(\"3-conv-layer net f1 score: \" + str(f1_score(y_v1, pred_y_v1, average=None)))\n",
    "print(\"3-conv-layer net accuracy: \" + str(accuracy_score(y_v1, pred_y_v1)))\n",
    "\n",
    "y_v2, pred_y_v2 = get_predictions_ys(model_t_v2, testloader)\n",
    "print(\"2-conv-layer net f1 score: \" + str(f1_score(y_v2, pred_y_v2, average=None)))\n",
    "print(\"2-conv-layer net accuracy: \" + str(accuracy_score(y_v2, pred_y_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 13.080\n",
      "[1,   600] loss: 4.194\n",
      "[2,   300] loss: 1.871\n",
      "[2,   600] loss: 5.305\n",
      "[3,   300] loss: 1.003\n",
      "[3,   600] loss: 3.374\n",
      "[4,   300] loss: 1.097\n",
      "[4,   600] loss: 1.832\n",
      "[5,   300] loss: 1.238\n",
      "[5,   600] loss: 1.315\n",
      "[6,   300] loss: 4.913\n",
      "[6,   600] loss: 0.178\n",
      "[7,   300] loss: 2.337\n",
      "[7,   600] loss: 2.275\n",
      "[8,   300] loss: 0.196\n",
      "[8,   600] loss: 12.094\n",
      "[9,   300] loss: 0.837\n",
      "[9,   600] loss: 0.340\n",
      "[10,   300] loss: 5.283\n",
      "[10,   600] loss: 0.730\n",
      "[11,   300] loss: 5.674\n",
      "[11,   600] loss: 3.058\n",
      "[12,   300] loss: 1.289\n",
      "[12,   600] loss: 0.688\n",
      "[13,   300] loss: 3.814\n",
      "[13,   600] loss: 0.569\n",
      "[14,   300] loss: 2.216\n",
      "[14,   600] loss: 0.276\n",
      "[15,   300] loss: 4.023\n",
      "[15,   600] loss: 6.348\n",
      "[16,   300] loss: 0.122\n",
      "[16,   600] loss: 2.820\n",
      "[17,   300] loss: 3.682\n",
      "[17,   600] loss: 8.774\n",
      "[18,   300] loss: 0.285\n",
      "[18,   600] loss: 8.966\n",
      "[19,   300] loss: 1.230\n",
      "[19,   600] loss: 4.512\n",
      "[20,   300] loss: 6.469\n",
      "[20,   600] loss: 6.002\n",
      "[21,   300] loss: 3.267\n",
      "[21,   600] loss: 0.045\n",
      "[22,   300] loss: 0.074\n",
      "[22,   600] loss: 6.188\n",
      "[23,   300] loss: 0.091\n",
      "[23,   600] loss: 2.988\n",
      "[24,   300] loss: 0.591\n",
      "[24,   600] loss: 1.181\n",
      "[25,   300] loss: 0.049\n",
      "[25,   600] loss: 0.106\n",
      "[26,   300] loss: 0.052\n",
      "[26,   600] loss: 0.869\n",
      "[27,   300] loss: 2.134\n",
      "[27,   600] loss: 0.141\n",
      "[28,   300] loss: 1.530\n",
      "[28,   600] loss: 0.130\n",
      "[29,   300] loss: 0.122\n",
      "[29,   600] loss: 0.227\n",
      "[30,   300] loss: 1.449\n",
      "[30,   600] loss: 0.452\n"
     ]
    }
   ],
   "source": [
    "encoder_loss_history__mse_test = train_model_self_reg(model_autoencoded, trainloader, criterion_base, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
