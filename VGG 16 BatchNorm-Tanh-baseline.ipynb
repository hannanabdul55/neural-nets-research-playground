{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import torchvision.datasets as datasets\n",
    "import time\n",
    "import vgg as vgg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg_test.VGG(vgg_test.make_layers(vgg_test.cfg['B'], batch_norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, 4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]), download=True),\n",
    "    batch_size=128, shuffle=True,\n",
    "    num_workers=5, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=128, shuffle=False,\n",
    "    num_workers=5, pin_memory=True)\n",
    "\n",
    "# define loss function (criterion) and pptimizer\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 3e-4,\n",
    "                                weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, writer=None):\n",
    "    \"\"\"\n",
    "        Run one train epoch\n",
    "    \"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, top1=top1))\n",
    "        writer.add_scalar('Loss/Train', losses.val)\n",
    "        writer.add_scalar('Prec@1', top1.val)\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "def validate(val_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Run evaluation\n",
    "    \"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top3 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,2,3))\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1[0].item(), input.size(0))\n",
    "        top3.update(prec1[2].item(), input.size(0))\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@3 {top3.val:.3f} ({top3.avg:.3f})'.format(\n",
    "                      i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                      top1=top1, top3=top3))\n",
    "\n",
    "    print(' * Prec@1 {top1.avg:.3f}'\n",
    "          .format(top1=top1))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 3.579 (3.579)\tData 0.151 (0.151)\tLoss 2.3348 (2.3348)\tPrec@1 7.031 (7.031)\n",
      "Epoch: [0][100/391]\tTime 3.315 (3.234)\tData 0.001 (0.002)\tLoss 1.6947 (1.8852)\tPrec@1 32.812 (27.050)\n",
      "Epoch: [0][200/391]\tTime 3.594 (3.226)\tData 0.001 (0.002)\tLoss 1.3795 (1.6886)\tPrec@1 48.438 (35.642)\n",
      "Epoch: [0][300/391]\tTime 3.258 (3.232)\tData 0.001 (0.001)\tLoss 1.2637 (1.5720)\tPrec@1 50.000 (40.949)\n",
      "Epoch: [1][0/391]\tTime 3.559 (3.559)\tData 0.067 (0.067)\tLoss 1.2761 (1.2761)\tPrec@1 55.469 (55.469)\n",
      "Epoch: [1][100/391]\tTime 3.314 (3.230)\tData 0.001 (0.001)\tLoss 1.0356 (1.1077)\tPrec@1 64.844 (60.388)\n",
      "Epoch: [1][200/391]\tTime 3.272 (3.233)\tData 0.001 (0.001)\tLoss 0.9901 (1.0648)\tPrec@1 66.406 (62.123)\n",
      "Epoch: [1][300/391]\tTime 3.223 (3.230)\tData 0.001 (0.001)\tLoss 0.9507 (1.0282)\tPrec@1 64.844 (63.541)\n",
      "Epoch: [2][0/391]\tTime 3.449 (3.449)\tData 0.066 (0.066)\tLoss 0.9287 (0.9287)\tPrec@1 69.531 (69.531)\n",
      "Epoch: [2][100/391]\tTime 3.181 (3.225)\tData 0.001 (0.001)\tLoss 0.8688 (0.8648)\tPrec@1 73.438 (70.684)\n",
      "Epoch: [2][200/391]\tTime 3.179 (3.225)\tData 0.001 (0.001)\tLoss 0.7883 (0.8470)\tPrec@1 70.312 (71.113)\n",
      "Epoch: [2][300/391]\tTime 3.172 (3.234)\tData 0.001 (0.001)\tLoss 0.8959 (0.8422)\tPrec@1 65.625 (71.255)\n",
      "Epoch: [3][0/391]\tTime 3.504 (3.504)\tData 0.068 (0.068)\tLoss 0.8090 (0.8090)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [3][100/391]\tTime 3.184 (3.241)\tData 0.001 (0.001)\tLoss 0.7645 (0.7447)\tPrec@1 75.000 (74.536)\n",
      "Epoch: [3][200/391]\tTime 3.408 (3.251)\tData 0.001 (0.001)\tLoss 0.7329 (0.7385)\tPrec@1 74.219 (75.031)\n",
      "Epoch: [3][300/391]\tTime 3.228 (3.251)\tData 0.001 (0.001)\tLoss 0.6076 (0.7279)\tPrec@1 78.125 (75.389)\n",
      "Epoch: [4][0/391]\tTime 3.514 (3.514)\tData 0.074 (0.074)\tLoss 0.7536 (0.7536)\tPrec@1 78.906 (78.906)\n",
      "Epoch: [4][100/391]\tTime 3.187 (3.252)\tData 0.001 (0.002)\tLoss 0.6336 (0.6715)\tPrec@1 79.688 (77.553)\n",
      "Epoch: [4][200/391]\tTime 3.198 (3.245)\tData 0.001 (0.001)\tLoss 0.5751 (0.6607)\tPrec@1 78.125 (77.907)\n",
      "Epoch: [4][300/391]\tTime 3.290 (3.247)\tData 0.001 (0.001)\tLoss 0.7605 (0.6578)\tPrec@1 74.219 (78.102)\n",
      "Epoch: [5][0/391]\tTime 3.570 (3.570)\tData 0.082 (0.082)\tLoss 0.6099 (0.6099)\tPrec@1 81.250 (81.250)\n",
      "Epoch: [5][100/391]\tTime 3.211 (3.256)\tData 0.001 (0.002)\tLoss 0.5819 (0.5973)\tPrec@1 81.250 (80.074)\n",
      "Epoch: [5][200/391]\tTime 3.310 (3.253)\tData 0.001 (0.001)\tLoss 0.4942 (0.5997)\tPrec@1 82.812 (80.045)\n",
      "Epoch: [5][300/391]\tTime 3.278 (3.251)\tData 0.001 (0.001)\tLoss 0.4756 (0.5975)\tPrec@1 81.250 (80.079)\n",
      "Epoch: [6][0/391]\tTime 3.673 (3.673)\tData 0.092 (0.092)\tLoss 0.5089 (0.5089)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [6][100/391]\tTime 3.211 (3.254)\tData 0.001 (0.002)\tLoss 0.5697 (0.5479)\tPrec@1 78.125 (82.116)\n",
      "Epoch: [6][200/391]\tTime 3.369 (3.257)\tData 0.001 (0.001)\tLoss 0.4261 (0.5561)\tPrec@1 85.938 (81.771)\n",
      "Epoch: [6][300/391]\tTime 3.212 (3.257)\tData 0.001 (0.001)\tLoss 0.4672 (0.5558)\tPrec@1 85.156 (81.686)\n",
      "Epoch: [7][0/391]\tTime 3.547 (3.547)\tData 0.074 (0.074)\tLoss 0.6733 (0.6733)\tPrec@1 75.781 (75.781)\n",
      "Epoch: [7][100/391]\tTime 3.286 (3.244)\tData 0.001 (0.001)\tLoss 0.5775 (0.5148)\tPrec@1 82.812 (83.037)\n",
      "Epoch: [7][200/391]\tTime 3.182 (3.244)\tData 0.001 (0.001)\tLoss 0.5284 (0.5166)\tPrec@1 78.125 (82.949)\n",
      "Epoch: [7][300/391]\tTime 3.396 (3.245)\tData 0.001 (0.001)\tLoss 0.5744 (0.5147)\tPrec@1 83.594 (82.909)\n",
      "Epoch: [8][0/391]\tTime 3.627 (3.627)\tData 0.070 (0.070)\tLoss 0.4356 (0.4356)\tPrec@1 83.594 (83.594)\n",
      "Epoch: [8][100/391]\tTime 3.288 (3.245)\tData 0.001 (0.001)\tLoss 0.3108 (0.4867)\tPrec@1 92.969 (84.097)\n",
      "Epoch: [8][200/391]\tTime 3.358 (3.243)\tData 0.001 (0.001)\tLoss 0.4285 (0.4924)\tPrec@1 85.938 (83.858)\n",
      "Epoch: [8][300/391]\tTime 3.239 (3.253)\tData 0.001 (0.001)\tLoss 0.5566 (0.4938)\tPrec@1 79.688 (83.778)\n",
      "Epoch: [9][0/391]\tTime 3.492 (3.492)\tData 0.068 (0.068)\tLoss 0.4533 (0.4533)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [9][100/391]\tTime 3.220 (3.252)\tData 0.001 (0.001)\tLoss 0.3388 (0.4574)\tPrec@1 91.406 (85.048)\n",
      "Epoch: [9][200/391]\tTime 3.224 (3.250)\tData 0.001 (0.001)\tLoss 0.3755 (0.4605)\tPrec@1 83.594 (84.814)\n",
      "Epoch: [9][300/391]\tTime 3.258 (3.248)\tData 0.001 (0.001)\tLoss 0.4132 (0.4654)\tPrec@1 86.719 (84.622)\n",
      "Epoch: [10][0/391]\tTime 3.633 (3.633)\tData 0.068 (0.068)\tLoss 0.6586 (0.6586)\tPrec@1 78.906 (78.906)\n",
      "Epoch: [10][100/391]\tTime 3.258 (3.255)\tData 0.001 (0.001)\tLoss 0.3457 (0.4387)\tPrec@1 89.062 (85.396)\n",
      "Epoch: [10][200/391]\tTime 3.155 (3.250)\tData 0.001 (0.001)\tLoss 0.4900 (0.4420)\tPrec@1 83.594 (85.374)\n",
      "Epoch: [10][300/391]\tTime 3.162 (3.251)\tData 0.001 (0.001)\tLoss 0.5642 (0.4432)\tPrec@1 85.156 (85.465)\n",
      "Epoch: [11][0/391]\tTime 3.523 (3.523)\tData 0.075 (0.075)\tLoss 0.2571 (0.2571)\tPrec@1 92.188 (92.188)\n",
      "Epoch: [11][100/391]\tTime 3.366 (3.258)\tData 0.001 (0.002)\tLoss 0.3527 (0.4176)\tPrec@1 92.188 (86.494)\n",
      "Epoch: [11][200/391]\tTime 3.220 (3.254)\tData 0.001 (0.001)\tLoss 0.3595 (0.4228)\tPrec@1 85.938 (86.190)\n",
      "Epoch: [11][300/391]\tTime 3.179 (3.251)\tData 0.001 (0.001)\tLoss 0.3042 (0.4201)\tPrec@1 89.062 (86.189)\n",
      "Epoch: [12][0/391]\tTime 3.576 (3.576)\tData 0.075 (0.075)\tLoss 0.4988 (0.4988)\tPrec@1 82.031 (82.031)\n",
      "Epoch: [12][100/391]\tTime 3.285 (3.259)\tData 0.001 (0.002)\tLoss 0.2656 (0.3872)\tPrec@1 89.844 (87.268)\n",
      "Epoch: [12][200/391]\tTime 3.255 (3.258)\tData 0.001 (0.001)\tLoss 0.2594 (0.3945)\tPrec@1 92.188 (86.956)\n",
      "Epoch: [12][300/391]\tTime 3.211 (3.255)\tData 0.001 (0.001)\tLoss 0.4516 (0.3960)\tPrec@1 85.156 (86.924)\n",
      "Epoch: [13][0/391]\tTime 3.205 (3.205)\tData 0.072 (0.072)\tLoss 0.3109 (0.3109)\tPrec@1 89.062 (89.062)\n",
      "Epoch: [13][100/391]\tTime 2.997 (3.049)\tData 0.001 (0.001)\tLoss 0.3373 (0.3960)\tPrec@1 87.500 (87.214)\n",
      "Epoch: [13][200/391]\tTime 3.153 (3.135)\tData 0.001 (0.001)\tLoss 0.3722 (0.3838)\tPrec@1 86.719 (87.449)\n",
      "Epoch: [13][300/391]\tTime 3.150 (3.168)\tData 0.001 (0.001)\tLoss 0.4297 (0.3868)\tPrec@1 85.938 (87.445)\n",
      "Epoch: [14][0/391]\tTime 3.441 (3.441)\tData 0.071 (0.071)\tLoss 0.3158 (0.3158)\tPrec@1 92.188 (92.188)\n",
      "Epoch: [14][100/391]\tTime 3.365 (3.203)\tData 0.001 (0.001)\tLoss 0.5359 (0.3551)\tPrec@1 81.250 (88.328)\n",
      "Epoch: [14][200/391]\tTime 3.141 (3.200)\tData 0.001 (0.001)\tLoss 0.3746 (0.3584)\tPrec@1 88.281 (88.207)\n",
      "Epoch: [14][300/391]\tTime 3.306 (3.197)\tData 0.001 (0.001)\tLoss 0.4273 (0.3679)\tPrec@1 88.281 (87.879)\n",
      "Epoch: [15][0/391]\tTime 3.578 (3.578)\tData 0.066 (0.066)\tLoss 0.2486 (0.2486)\tPrec@1 92.969 (92.969)\n",
      "Epoch: [15][100/391]\tTime 3.454 (3.222)\tData 0.001 (0.001)\tLoss 0.2021 (0.3512)\tPrec@1 94.531 (88.204)\n",
      "Epoch: [15][200/391]\tTime 2.851 (3.121)\tData 0.001 (0.001)\tLoss 0.3332 (0.3486)\tPrec@1 88.281 (88.495)\n",
      "Epoch: [15][300/391]\tTime 2.874 (3.033)\tData 0.001 (0.001)\tLoss 0.2821 (0.3535)\tPrec@1 90.625 (88.377)\n",
      "Epoch: [16][0/391]\tTime 3.086 (3.086)\tData 0.061 (0.061)\tLoss 0.3310 (0.3310)\tPrec@1 89.062 (89.062)\n",
      "Epoch: [16][100/391]\tTime 2.820 (2.853)\tData 0.001 (0.001)\tLoss 0.4411 (0.3323)\tPrec@1 85.156 (89.132)\n",
      "Epoch: [16][200/391]\tTime 2.826 (2.851)\tData 0.001 (0.001)\tLoss 0.3217 (0.3407)\tPrec@1 89.844 (88.829)\n",
      "Epoch: [16][300/391]\tTime 3.146 (2.853)\tData 0.001 (0.001)\tLoss 0.1888 (0.3457)\tPrec@1 94.531 (88.673)\n",
      "Epoch: [17][0/391]\tTime 3.178 (3.178)\tData 0.062 (0.062)\tLoss 0.4306 (0.4306)\tPrec@1 86.719 (86.719)\n",
      "Epoch: [17][100/391]\tTime 3.006 (3.246)\tData 0.001 (0.001)\tLoss 0.4585 (0.3194)\tPrec@1 82.812 (89.434)\n",
      "Epoch: [17][200/391]\tTime 3.360 (3.266)\tData 0.001 (0.001)\tLoss 0.4241 (0.3229)\tPrec@1 83.594 (89.319)\n",
      "Epoch: [17][300/391]\tTime 3.191 (3.237)\tData 0.001 (0.001)\tLoss 0.3501 (0.3235)\tPrec@1 89.844 (89.387)\n",
      "Epoch: [18][0/391]\tTime 3.269 (3.269)\tData 0.072 (0.072)\tLoss 0.2730 (0.2730)\tPrec@1 90.625 (90.625)\n",
      "Epoch: [18][100/391]\tTime 3.332 (3.287)\tData 0.001 (0.001)\tLoss 0.3895 (0.3079)\tPrec@1 87.500 (89.859)\n",
      "Epoch: [18][200/391]\tTime 2.880 (3.177)\tData 0.001 (0.001)\tLoss 0.2190 (0.3065)\tPrec@1 92.188 (89.964)\n",
      "Epoch: [18][300/391]\tTime 2.911 (3.079)\tData 0.001 (0.001)\tLoss 0.3448 (0.3086)\tPrec@1 87.500 (89.836)\n",
      "Epoch: [19][0/391]\tTime 3.117 (3.117)\tData 0.063 (0.063)\tLoss 0.3020 (0.3020)\tPrec@1 91.406 (91.406)\n",
      "Epoch: [19][100/391]\tTime 2.862 (2.864)\tData 0.001 (0.001)\tLoss 0.3090 (0.3010)\tPrec@1 90.625 (90.261)\n",
      "Epoch: [19][200/391]\tTime 3.076 (2.874)\tData 0.001 (0.001)\tLoss 0.2042 (0.3008)\tPrec@1 95.312 (90.283)\n",
      "Epoch: [19][300/391]\tTime 3.279 (2.992)\tData 0.001 (0.001)\tLoss 0.2810 (0.3033)\tPrec@1 92.188 (90.124)\n"
     ]
    }
   ],
   "source": [
    "train_epochs = 20\n",
    "writer = SummaryWriter('batchnorm_base', flush_secs=10)\n",
    "for i in range(train_epochs):\n",
    "    train(train_loader, model, criterion, optimizer, i, writer=writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 1.311 (1.311)\tLoss 0.4082 (0.4082)\tPrec@1 84.375 (84.375)\tPrec@3 98.438 (98.438)\n",
      " * Prec@1 84.630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.63"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_base.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wo = torchvision.models.vgg11()\n",
    "optimizer_wo = torch.optim.Adam(model_wo.parameters(), 3e-4,\n",
    "                                weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10000][0/391]\tTime 5.464 (5.464)\tData 0.072 (0.072)\tLoss 1.1889 (1.1889)\tPrec@1 57.812 (57.812)\n",
      "Epoch: [10000][50/391]\tTime 3.341 (3.419)\tData 0.001 (0.002)\tLoss 1.1646 (1.2292)\tPrec@1 54.688 (56.020)\n",
      "Epoch: [10000][100/391]\tTime 3.523 (3.383)\tData 0.001 (0.001)\tLoss 1.1371 (1.2004)\tPrec@1 57.812 (57.356)\n",
      "Epoch: [10000][150/391]\tTime 3.304 (3.403)\tData 0.001 (0.001)\tLoss 0.9491 (1.1710)\tPrec@1 60.938 (58.371)\n",
      "Epoch: [10000][200/391]\tTime 3.264 (3.386)\tData 0.001 (0.001)\tLoss 1.1725 (1.1639)\tPrec@1 57.031 (58.660)\n",
      "Epoch: [10000][250/391]\tTime 3.291 (3.365)\tData 0.001 (0.001)\tLoss 1.0466 (1.1535)\tPrec@1 58.594 (59.008)\n",
      "Epoch: [10000][300/391]\tTime 3.266 (3.359)\tData 0.001 (0.001)\tLoss 1.1317 (1.1394)\tPrec@1 60.156 (59.406)\n",
      "Epoch: [10000][350/391]\tTime 3.211 (3.353)\tData 0.001 (0.001)\tLoss 1.1335 (1.1278)\tPrec@1 56.250 (59.894)\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, model_wo, criterion, optimizer_wo, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error: 0.446\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-185059696e6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation_error: {.3f} '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mget_model_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "print('validation_error: ' , get_model_error(model, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
